{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI助手，没有实际年龄。我很高兴能与您交流，为您提供帮助。\n"
     ]
    }
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI助手，没有实际年龄。我很高兴能与您交流，为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key='sk-4a47da58c2e64a53bc7b94d0892016be',\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\",  # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': '你几岁了？？'}\n",
    "        ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User>\t How's the weather in Hangzhou?\n",
      "Model>\t The current weather in Hangzhou is 24°C.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def send_messages(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    return response.choices[0].message\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-fd20bf9c2c0f4c9ea49ae5ed53037504\",\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get weather of an location, the user shoud supply a location first\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"How's the weather in Hangzhou?\"}]\n",
    "message = send_messages(messages)\n",
    "print(f\"User>\\t {messages[0]['content']}\")\n",
    "\n",
    "tool = message.tool_calls[0]\n",
    "messages.append(message)\n",
    "\n",
    "messages.append({\"role\": \"tool\", \"tool_call_id\": tool.id, \"content\": \"24℃\"})\n",
    "message = send_messages(messages)\n",
    "print(f\"Model>\\t {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"How's the weather in Hangzhou?\"},\n",
       " ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0_5b2423d7-8642-4808-aed4-ed6accc87ead', function=Function(arguments='{\"location\":\"Hangzhou\"}', name='get_weather'), type='function', index=0)]),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_0_5b2423d7-8642-4808-aed4-ed6accc87ead',\n",
       "  'content': '24℃'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"How's the weather in Hangzhou?\"}]\n",
    "response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0_426f7148-722f-4722-ac83-c8f70d939a9f', function=Function(arguments='{\"location\":\"Hangzhou\"}', name='get_weather'), type='function', index=0)]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "def upload_image_to_imgbb(image_path: str, max_size: int = 512) -> str:\n",
    "    # Open the image and resize it\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize image if needed (preserve aspect ratio)\n",
    "    width, height = image.size\n",
    "    if width > max_size or height > max_size:\n",
    "        if width > height:\n",
    "            new_width = max_size\n",
    "            new_height = int(height * (max_size / width))\n",
    "        else:\n",
    "            new_height = max_size\n",
    "            new_width = int(width * (max_size / height))\n",
    "        image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    \n",
    "    # Save to buffer\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Upload the resized image\n",
    "    response = requests.post(\n",
    "        \"https://api.imgbb.com/1/upload\",\n",
    "        params={\"key\": '9689e42764a7f935277d8371a415dc4d'},\n",
    "        files={\"image\": buffer}\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"data\"][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url  = upload_image_to_imgbb(\"/Users/yingcongchen/Downloads/Picture1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "https://i.ibb.co/8LGxq0Bx/image.png\n",
      "--------------------------------\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': 'InvalidParameter.DataInspection', 'param': None, 'message': 'Download the media resource timed out during the data inspection process.', 'type': 'InvalidParameter.DataInspection'}, 'id': 'chatcmpl-0983b101-9628-928c-8cd2-cf2848f4764d', 'request_id': '0983b101-9628-928c-8cd2-cf2848f4764d'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m     16\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQWEN_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     17\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://dashscope.aliyuncs.com/compatible-mode/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqwen-vl-plus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 此处以qwen-vl-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m请分析这张图像的内容\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://i.ibb.co/bRXX1Yz6/image.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/AI原生开发/EnvisionCore-evolve/EnvisionCore-v2/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/AI原生开发/EnvisionCore-evolve/EnvisionCore-v2/.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/AI原生开发/EnvisionCore-evolve/EnvisionCore-v2/.venv/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/code/AI原生开发/EnvisionCore-evolve/EnvisionCore-v2/.venv/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/AI原生开发/EnvisionCore-evolve/EnvisionCore-v2/.venv/lib/python3.10/site-packages/openai/_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1032\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'InvalidParameter.DataInspection', 'param': None, 'message': 'Download the media resource timed out during the data inspection process.', 'type': 'InvalidParameter.DataInspection'}, 'id': 'chatcmpl-0983b101-9628-928c-8cd2-cf2848f4764d', 'request_id': '0983b101-9628-928c-8cd2-cf2848f4764d'}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "image_url = upload_image_to_imgbb(\"/Users/yingcongchen/Downloads/近照.jpg\")\n",
    "print(\"--------------------------------\")\n",
    "print(image_url)\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('QWEN_API_KEY'),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-vl-plus\",  # 此处以qwen-vl-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"请分析这张图像的内容\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://i.ibb.co/bRXX1Yz6/image.png\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "def format_tools_description(tools: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Format tool descriptions for inclusion in prompts.\n",
    "    \n",
    "    Args:\n",
    "        tools: List of available tools\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string describing available tools\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    # Add a concise guide for tool calling at the beginning\n",
    "    format_explanation = \"\"\" Note that only the following tools are available:\n",
    "\"\"\"\n",
    "    descriptions.append(format_explanation)\n",
    "    \n",
    "    # Generate description for each tool\n",
    "    for tool in tools:\n",
    "        name = tool.get(\"function\", {}).get(\"name\")\n",
    "        description = tool.get(\"function\", {}).get(\"description\")\n",
    "        params = tool.get(\"function\", {}).get(\"parameters\", {}).get(\"properties\", {})\n",
    "        required_params = tool.get(\"function\", {}).get(\"parameters\", {}).get(\"required\", [])\n",
    "        \n",
    "        if not name or not description:\n",
    "            continue\n",
    "            \n",
    "        # Format parameter descriptions\n",
    "        param_desc = []\n",
    "        for param_name, param_info in params.items():\n",
    "            param_type = param_info.get(\"type\", \"any\")\n",
    "            param_description = param_info.get(\"description\", \"\")\n",
    "            required = \"required\" if param_name in required_params else \"optional\"\n",
    "            param_desc.append(f\"  - {param_name} ({param_type}, {required}): {param_description}\")\n",
    "            \n",
    "        param_text = \"\\n\".join(param_desc) if param_desc else \"  No parameters\"\n",
    "        \n",
    "        # # Create a simple example with actual parameter names\n",
    "        # example_args = {}\n",
    "        # for param_name in params:\n",
    "        #     if param_name in required_params:\n",
    "        #         if params[param_name].get(\"type\") == \"number\" or params[param_name].get(\"type\") == \"integer\":\n",
    "        #             example_args[param_name] = 0\n",
    "        #         else:\n",
    "        #             example_args[param_name] = f\"<{param_name}>\"\n",
    "        \n",
    "        # example = f\"\"\"Example: {{\"name\": \"{name}\", \"arguments\": {json.dumps(example_args)}}}\"\"\"\n",
    "            \n",
    "        # Combine all into the tool description\n",
    "        descriptions.append(f\"Tool: {name}\\nDescription: {description}\\nParameters:\\n{param_text}\")\n",
    "        \n",
    "    return \"\\n\\n\".join(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_tools_description(tools: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Format tool descriptions for inclusion in prompts.\n",
    "    \n",
    "    Args:\n",
    "        tools: List of available tools\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string describing available tools\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    for tool in tools:\n",
    "        name = tool.get(\"function\", {}).get(\"name\")\n",
    "        description = tool.get(\"function\", {}).get(\"description\")\n",
    "        params = tool.get(\"function\", {}).get(\"parameters\", {}).get(\"properties\", {})\n",
    "        \n",
    "        if not name or not description:\n",
    "            continue\n",
    "            \n",
    "        param_desc = []\n",
    "        for param_name, param_info in params.items():\n",
    "            param_type = param_info.get(\"type\", \"any\")\n",
    "            param_description = param_info.get(\"description\", \"\")\n",
    "            param_desc.append(f\"  - {param_name} ({param_type}): {param_description}\")\n",
    "            \n",
    "        param_text = \"\\n\".join(param_desc) if param_desc else \"  No parameters\"\n",
    "        descriptions.append(f\"- {name}: {description}\\n  Parameters:\\n{param_text}\")\n",
    "    return \"\\n\\n\".join(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- get_weather: Get weather of a location, the user should supply a location first\n",
      "  Parameters:\n",
      "  - location (string): The city and state, e.g. San Francisco, CA\n",
      "\n",
      "- search_restaurants: Search for restaurants in a specific area with optional cuisine type\n",
      "  Parameters:\n",
      "  - location (string): The city or area to search in\n",
      "  - cuisine (string): Type of cuisine (e.g., Italian, Chinese, etc.)\n",
      "  - price_range (integer): Price range from 1 (cheap) to 4 (expensive)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get weather of a location, the user should supply a location first\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_restaurants\",\n",
    "            \"description\": \"Search for restaurants in a specific area with optional cuisine type\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city or area to search in\"\n",
    "                    },\n",
    "                    \"cuisine\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Type of cuisine (e.g., Italian, Chinese, etc.)\"\n",
    "                    },\n",
    "                    \"price_range\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Price range from 1 (cheap) to 4 (expensive)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(format_tools_description(tools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playground>playground2>playground3\n"
     ]
    }
   ],
   "source": [
    "from FractFlow.infra.config import ConfigManager\n",
    "\n",
    "# Create a config manager instance\n",
    "config = ConfigManager()\n",
    "config.push_to_call_path(\"playground\")\n",
    "config.push_to_call_path(\"playground2\")\n",
    "config.push_to_call_path(\"playground3\")\n",
    "# config.pop_from_call_path()\n",
    "# Print the current configuration\n",
    "print(config.get_call_path())\n",
    "# print(json.dumps(config.get_config(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 13:30:04\u001b[0m \u001b[34m\u001b[1m[DEBUG]\u001b[0m \u001b[36mtest_logger\u001b[0m: \u001b[34m\u001b[1mThis is a test message\u001b[0m | {'logger_name': 'test_logger', 'name': 'test', 'path': './test.py'}\n",
      "\u001b[32m2025-04-22 13:30:04\u001b[0m \u001b[34m\u001b[1m[DEBUG]\u001b[0m \u001b[36mtest_logger\u001b[0m: \u001b[34m\u001b[1mThis is a test message\u001b[0m | {'logger_name': 'test_logger', 'name': 'test', 'path': './test.py'}\n",
      "\u001b[32m2025-04-22 13:30:04\u001b[0m \u001b[34m\u001b[1m[DEBUG]\u001b[0m \u001b[36mtest_logger\u001b[0m: \u001b[34m\u001b[1mThis is a test message\u001b[0m | {'logger_name': 'test_logger', 'name': 'test', 'path': './test.py'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current implementation (showing the issue):\n",
      "\n",
      "Fixed format solution:\n",
      "\n",
      "Improved context handling solution:\n"
     ]
    }
   ],
   "source": [
    "# Test function for logging_utils.py\n",
    "import sys\n",
    "from typing import Any, Dict, Optional\n",
    "from loguru import logger\n",
    "\n",
    "# Copy of the relevant parts of the logging code\n",
    "def setup_test_logging():\n",
    "    # Remove any existing handlers\n",
    "    logger.remove()\n",
    "    \n",
    "    # Define format - this is the problematic format with duplicate data\n",
    "    log_format = \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> <level>[{level}]</level> <cyan>{extra[logger_name]}</cyan>: <level>{message}</level> | {extra}\"\n",
    "    \n",
    "    # Add console handler with coloring\n",
    "    logger.add(\n",
    "        sys.stderr,\n",
    "        format=log_format,\n",
    "        level=\"DEBUG\",\n",
    "        colorize=True,\n",
    "    )\n",
    "\n",
    "class TestLoggerWrapper:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    def _format_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Filter out keys that would duplicate output or clutter console.\"\"\"\n",
    "        return {\n",
    "            k: v for k, v in data.items()\n",
    "            if k not in {\"logger_name\", \"message\"} and not k.startswith(\"_\")\n",
    "        }\n",
    "    \n",
    "    def _log(self, level: str, message: str, data: Optional[Dict[str, Any]] = None):\n",
    "        context = {\"logger_name\": self.name}\n",
    "        if data:\n",
    "            context.update(self._format_data(data))\n",
    "        logger.bind(**context).log(level, message)\n",
    "    \n",
    "    def debug(self, message: str, data: Optional[Dict[str, Any]] = None):\n",
    "        self._log(\"DEBUG\", message, data)\n",
    "\n",
    "# Run test with current implementation (shows the problem)\n",
    "def test_current_implementation():\n",
    "    setup_test_logging()\n",
    "    test_logger = TestLoggerWrapper(\"test_logger\")\n",
    "    test_logger.debug(\"This is a test message\", {\"name\": \"test\", \"path\": \"./test.py\"})\n",
    "\n",
    "# Test with fixed log format (solution 1)\n",
    "def test_fixed_format():\n",
    "    logger.remove()\n",
    "    # Updated format that doesn't repeat message and formats extra better\n",
    "    log_format = \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> <level>[{level}]</level> <cyan>{extra[logger_name]}</cyan>: <level>{message}</level> | {extra}\"\n",
    "    logger.add(sys.stderr, format=log_format, level=\"DEBUG\", colorize=True)\n",
    "    \n",
    "    test_logger = TestLoggerWrapper(\"test_logger\")\n",
    "    test_logger.debug(\"This is a test message\", {\"name\": \"test\", \"path\": \"./test.py\"})\n",
    "\n",
    "# Test with improved context handling (solution 2)\n",
    "class ImprovedLoggerWrapper(TestLoggerWrapper):\n",
    "    def _log(self, level: str, message: str, data: Optional[Dict[str, Any]] = None):\n",
    "        # Create context with logger_name for display in format\n",
    "        display_context = {\"logger_name\": self.name}\n",
    "        \n",
    "        # Create filtered data for the extra output\n",
    "        extra_context = {}\n",
    "        if data:\n",
    "            extra_context = self._format_data(data)\n",
    "            \n",
    "        # Combine contexts\n",
    "        context = {**display_context, **extra_context}\n",
    "        logger.bind(**context).log(level, message)\n",
    "\n",
    "def test_improved_implementation():\n",
    "    setup_test_logging()\n",
    "    test_logger = ImprovedLoggerWrapper(\"test_logger\")\n",
    "    test_logger.debug(\"This is a test message\", {\"name\": \"test\", \"path\": \"./test.py\"})\n",
    "\n",
    "# Run the tests\n",
    "print(\"Current implementation (showing the issue):\")\n",
    "test_current_implementation()\n",
    "\n",
    "print(\"\\nFixed format solution:\")\n",
    "test_fixed_format()\n",
    "\n",
    "print(\"\\nImproved context handling solution:\")\n",
    "test_improved_implementation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 13:33:59\u001b[0m \u001b[34m\u001b[1m[DEBUG]\u001b[0m \u001b[36mtest_logger\u001b[0m: \u001b[34m\u001b[1mThis is a test message\u001b[0m | {'name': 'test', 'path': './test.py'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import Any, Dict, Optional\n",
    "from loguru import logger\n",
    "\n",
    "# Solution: Use a custom sink that filters out logger_name from the record['extra']\n",
    "class FilteredExtraSink:\n",
    "    def __init__(self, sink):\n",
    "        self.sink = sink\n",
    "    \n",
    "    def write(self, message):\n",
    "        import re\n",
    "        # Replace the extra dictionary rendering to exclude logger_name\n",
    "        message = re.sub(r\"'logger_name': '[^']*'(, )?\", \"\", message)\n",
    "        self.sink.write(message)\n",
    "    \n",
    "    def flush(self):\n",
    "        self.sink.flush()\n",
    "\n",
    "def setup_filtered_logging():\n",
    "    logger.remove()\n",
    "    log_format = \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> <level>[{level}]</level> <cyan>{extra[logger_name]}</cyan>: <level>{message}</level> | {extra}\"\n",
    "    \n",
    "    # Use the filtered sink instead of directly writing to stderr\n",
    "    logger.add(\n",
    "        FilteredExtraSink(sys.stderr),\n",
    "        format=log_format,\n",
    "        level=\"DEBUG\",\n",
    "        colorize=True,\n",
    "    )\n",
    "\n",
    "class TestLoggerWrapper:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    def _format_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"This doesn't actually remove logger_name from the final output\"\"\"\n",
    "        return {\n",
    "            k: v for k, v in data.items()\n",
    "            if k not in {\"logger_name\", \"message\"} and not k.startswith(\"_\")\n",
    "        }\n",
    "    \n",
    "    def _log(self, level: str, message: str, data: Optional[Dict[str, Any]] = None):\n",
    "        context = {\"logger_name\": self.name}\n",
    "        if data:\n",
    "            context.update(self._format_data(data))\n",
    "        logger.bind(**context).log(level, message)\n",
    "    \n",
    "    def debug(self, message: str, data: Optional[Dict[str, Any]] = None):\n",
    "        self._log(\"DEBUG\", message, data)\n",
    "\n",
    "# Test with custom sink solution\n",
    "def test_filtered_sink():\n",
    "    setup_filtered_logging()\n",
    "    test_logger = TestLoggerWrapper(\"test_logger\")\n",
    "    test_logger.debug(\"This is a test message\", {\"name\": \"test\", \"path\": \"./test.py\"})\n",
    "\n",
    "# Run the test\n",
    "test_filtered_sink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 13:57:23\u001b[0m \u001b[34m\u001b[1m[DEBUG]\u001b[0m \u001b[36mtest_logger\u001b[0m: \u001b[34m\u001b[1mThis is a test message\u001b[0m | {'logger_name': 'test_logger', 'info': 'test'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root logger level: 10\n"
     ]
    }
   ],
   "source": [
    "from FractFlow.infra.logging_utils import get_logger, setup_logging\n",
    "\n",
    "setup_logging(10)\n",
    "\n",
    "logger = get_logger(\"test_logger\")\n",
    "logger.debug(\"This is a test message\", {'info': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 14:05:46\u001b[0m \u001b[34m\u001b[1m[DEBUG]\u001b[0m \u001b[36mtest_logger\u001b[0m: \u001b[34m\u001b[1mThis is a test message\u001b[0m | {'logger_name': 'test_logger'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root logger level: 10\n"
     ]
    }
   ],
   "source": [
    "from FractFlow.infra.logging_utils import get_logger, setup_logging\n",
    "\n",
    "setup_logging(10)\n",
    "\n",
    "logger = get_logger(\"test_logger\")\n",
    "logger.debug(\"This is a test message\", {'info': 'test'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3828741391.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from /Users/yingcongchen/Documents/code/AI原生开发/EnvisionCore-evolve/FractFlow/tools.editor import server\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from ..tools.editor import server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yingcongchen/Documents/code/AI原生开发/EnvisionCore-evolve/FractFlow/tests'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
